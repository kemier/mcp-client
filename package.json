{
  "name": "mcp-server-manager",
  "displayName": "MCP Server Manager",
  "description": "Manage Model Context Protocol (MCP) servers for AI assistants",
  "version": "0.1.0",
  "type": "module",
  "engines": {
    "vscode": "^1.60.0"
  },
  "categories": [
    "Other"
  ],
  "activationEvents": [
    "*"
  ],
  "main": "./out/cjs/extension.js",
  "contributes": {
    "commands": [
      {
        "command": "mcpServerManager.showDashboard",
        "title": "MCP: Show Server Dashboard",
        "category": "MCP Server Manager"
      },
      {
        "command": "mcpServerManager.addServer",
        "title": "MCP: Add Server",
        "category": "MCP Server Manager"
      },
      {
        "command": "mcpServerManager.startServer",
        "title": "MCP: Start Server",
        "category": "MCP Server Manager"
      },
      {
        "command": "mcpServerManager.stopServer",
        "title": "MCP: Stop Server",
        "category": "MCP Server Manager"
      },
      {
        "command": "mcpServerManager.removeServer",
        "title": "MCP: Remove Server",
        "category": "MCP Server Manager"
      },
      {
        "command": "mcpServerManager.refreshCapabilities",
        "title": "MCP: Refresh Server Capabilities",
        "category": "MCP Server Manager"
      },
      {
        "command": "mcpServerManager.showLogs",
        "title": "MCP: Show Logs",
        "category": "MCP Server Manager"
      }
    ],
    "configuration": {
      "title": "MCP Server Manager",
      "properties": {
        "mcpServerManager.autoStartServers": {
          "type": "boolean",
          "default": false,
          "description": "Automatically start all configured MCP tool servers when the extension activates."
        },
        "mcpServerManager.inferenceServerIp": {
          "type": "string",
          "default": "127.0.0.1",
          "description": "The IP address of the running local LLM inference server (NOTE: Currently unused by the extension connection logic)."
        },
        "mcpServerManager.inferenceServerPort": {
          "type": "number",
          "default": 8080,
          "description": "The port number of the running local LLM inference server (NOTE: Currently unused by the extension connection logic)."
        }
      }
    },
    "viewsContainers": {
      "activitybar": [
        {
          "id": "mcp-manager-sidebar",
          "title": "MCP Manager",
          "icon": "$(beaker)"
        }
      ]
    },
    "views": {
      "mcp-manager-sidebar": [
        {
          "id": "mcpChatView",
          "name": "MCP Chat",
          "type": "webview",
          "contextualTitle": "MCP Chat"
        }
      ]
    }
  },
  "scripts": {
    "vscode:prepublish": "npm run compile",
    "compile": "tsc -p ./ && tsc -p tsconfig.cjs.json",
    "watch": "tsc -watch -p ./ & tsc -watch -p tsconfig.cjs.json",
    "pretest": "npm run compile && npm run lint",
    "lint": "eslint src --ext ts",
    "test": "node ./out/test/runTest.js"
  },
  "devDependencies": {
    "@types/cross-spawn": "^6.0.6",
    "@types/mocha": "^10.0.10",
    "@types/node": "^18.19.86",
    "@types/vscode": "^1.60.0",
    "@typescript-eslint/eslint-plugin": "^5.30.0",
    "@typescript-eslint/parser": "^5.30.0",
    "eslint": "^8.18.0",
    "typescript": "^5.8.3"
  },
  "dependencies": {
    "@modelcontextprotocol/sdk": "^1.10.1",
    "dotenv": "^16.5.0"
  }
}
